{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e828ba2",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "715d4af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in ./.venv/lib/python3.9/site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in ./.venv/lib/python3.9/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (from catboost) (3.9.4)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in ./.venv/lib/python3.9/site-packages (from catboost) (2.0.2)\n",
      "Requirement already satisfied: pandas>=0.24 in ./.venv/lib/python3.9/site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.9/site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in ./.venv/lib/python3.9/site-packages (from catboost) (6.5.0)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.9/site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (3.2.5)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.23.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./.venv/lib/python3.9/site-packages (from plotly->catboost) (2.13.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./.venv/lib/python3.9/site-packages (from plotly->catboost) (2.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "All packages loaded successfully!\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "All packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install missing package for Jupyter (magic command)\n",
    "%pip install catboost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, classification_report,\n",
    "    confusion_matrix, log_loss, brier_score_loss, roc_curve\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "print(\"All packages loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9636e16",
   "metadata": {},
   "source": [
    "## 2. Load L10 Dataset (Best Performing Window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e484c1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 5,145 matchups\n",
      "Seasons: [np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
      "\n",
      "Games per season:\n",
      "season\n",
      "2022    1290\n",
      "2023    1288\n",
      "2024    1285\n",
      "2025    1282\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the L10 dataset (confirmed as best from LASSO analysis)\n",
    "df_L10 = pd.read_csv('nba_matchups_with_features_L10.csv')\n",
    "\n",
    "# Convert date columns\n",
    "df_L10['date'] = pd.to_datetime(df_L10['date'])\n",
    "\n",
    "print(f\"Dataset loaded: {len(df_L10):,} matchups\")\n",
    "print(f\"Seasons: {sorted(df_L10['season'].unique())}\")\n",
    "print(f\"\\nGames per season:\")\n",
    "print(df_L10['season'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359da98",
   "metadata": {},
   "source": [
    "## 3. Define Features and Create Train/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "264ac1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base features (L10): 18\n",
      "\n",
      "Features:\n",
      "   1. off_rtg_L10_diff\n",
      "   2. def_rtg_L10_diff\n",
      "   3. net_rtg_L10_diff\n",
      "   4. efg_pct_L10_diff\n",
      "   5. 3p_pct_L10_diff\n",
      "   6. 3pa_rate_L10_diff\n",
      "   7. win_pct_L10_diff\n",
      "   8. to_pct_L10_diff\n",
      "   9. ft_rate_L10_diff\n",
      "  10. oreb_pct_L10_diff\n",
      "  11. ast_ratio_L10_diff\n",
      "  12. stl_pct_L10_diff\n",
      "  13. blk_pct_L10_diff\n",
      "  14. pts_std_L10_diff\n",
      "  15. win_streak_diff\n",
      "  16. rest_advantage\n",
      "  17. is_b2b_home\n",
      "  18. is_b2b_away\n"
     ]
    }
   ],
   "source": [
    "def get_features_L10():\n",
    "    \"\"\"\n",
    "    Return list of base features for L10 window.\n",
    "    Features are differential (away - home) unless noted.\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        # Advanced Efficiency Gaps\n",
    "        'off_rtg_L10_diff',       # Offensive efficiency gap\n",
    "        'def_rtg_L10_diff',       # Defensive efficiency gap\n",
    "        'net_rtg_L10_diff',       # Net rating gap\n",
    "        \n",
    "        # Shooting Efficiency Gaps\n",
    "        'efg_pct_L10_diff',       # Effective FG% gap\n",
    "        '3p_pct_L10_diff',        # 3-point shooting gap\n",
    "        '3pa_rate_L10_diff',      # 3-point volume gap\n",
    "        \n",
    "        # Form/Momentum\n",
    "        'win_pct_L10_diff',       # Recent win percentage gap\n",
    "        \n",
    "        # Ball Control\n",
    "        'to_pct_L10_diff',        # Turnover rate gap\n",
    "        'ft_rate_L10_diff',       # Free throw rate gap\n",
    "        \n",
    "        # Rebounding & Playmaking\n",
    "        'oreb_pct_L10_diff',      # Offensive rebounding gap\n",
    "        'ast_ratio_L10_diff',     # Assist ratio gap\n",
    "        \n",
    "        # Defensive Stats\n",
    "        'stl_pct_L10_diff',       # Steal percentage gap\n",
    "        'blk_pct_L10_diff',       # Block percentage gap\n",
    "        \n",
    "        # Consistency & Momentum (non-window features)\n",
    "        'pts_std_L10_diff',       # Scoring consistency gap\n",
    "        'win_streak_diff',        # Win streak differential\n",
    "        \n",
    "        # Rest/Fatigue\n",
    "        'rest_advantage',         # Rest days advantage\n",
    "        'is_b2b_home',            # Home team back-to-back\n",
    "        'is_b2b_away'             # Away team back-to-back\n",
    "    ]\n",
    "    \n",
    "    return features\n",
    "\n",
    "features_L10 = get_features_L10()\n",
    "\n",
    "print(f\"Base features (L10): {len(features_L10)}\")\n",
    "print(\"\\nFeatures:\")\n",
    "for i, f in enumerate(features_L10, 1):\n",
    "    print(f\"  {i:2d}. {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87b86caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "L10 Dataset Split:\n",
      "============================================================\n",
      "Train: 3,863 games (seasons ≤ 2024)\n",
      "Test:  1,282 games (season 2025)\n",
      "Train away win rate: 44.1%\n",
      "Test away win rate:  45.2%\n",
      "\n",
      "============================================================\n",
      "Three-Way Split (Training + Calibration + Test):\n",
      "============================================================\n",
      "\n",
      "Training (model fit + CV):   2,897 games (75%)\n",
      "Calibration (isotonic fit): 966 games (25%)\n",
      "Test (final eval):          1,282 games (2025)\n",
      "\n",
      "Training away win rate: 42.3%\n",
      "Calibration away win rate: 49.4%\n",
      "Test away win rate: 45.2%\n",
      "Train: 3,863 games (seasons ≤ 2024)\n",
      "Test:  1,282 games (season 2025)\n",
      "Train away win rate: 44.1%\n",
      "Test away win rate:  45.2%\n",
      "\n",
      "============================================================\n",
      "Three-Way Split (Training + Calibration + Test):\n",
      "============================================================\n",
      "\n",
      "Training (model fit + CV):   2,897 games (75%)\n",
      "Calibration (isotonic fit): 966 games (25%)\n",
      "Test (final eval):          1,282 games (2025)\n",
      "\n",
      "Training away win rate: 42.3%\n",
      "Calibration away win rate: 49.4%\n",
      "Test away win rate: 45.2%\n"
     ]
    }
   ],
   "source": [
    "def create_train_test_split(df, features, target='win_away'):\n",
    "    \"\"\"\n",
    "    Split data into train (≤2024) and test (2025) sets.\n",
    "    Returns X_train, X_test, y_train, y_test, dates\n",
    "    \"\"\"\n",
    "    # Verify all features exist\n",
    "    missing = [f for f in features if f not in df.columns]\n",
    "    if missing:\n",
    "        print(f\"Warning: Missing features: {missing}\")\n",
    "        features = [f for f in features if f in df.columns]\n",
    "    \n",
    "    # Drop any rows with missing values in features or target\n",
    "    df_clean = df.dropna(subset=features + [target])\n",
    "    \n",
    "    # Split by season\n",
    "    train_mask = df_clean['season'] <= 2024\n",
    "    test_mask = df_clean['season'] == 2025\n",
    "    \n",
    "    X_train = df_clean.loc[train_mask, features].copy()\n",
    "    X_test = df_clean.loc[test_mask, features].copy()\n",
    "    y_train = df_clean.loc[train_mask, target].copy()\n",
    "    y_test = df_clean.loc[test_mask, target].copy()\n",
    "    \n",
    "    # Store dates for analysis\n",
    "    dates_train = df_clean.loc[train_mask, 'date'].copy()\n",
    "    dates_test = df_clean.loc[test_mask, 'date'].copy()\n",
    "    \n",
    "    print(f\"Train: {len(X_train):,} games (seasons ≤ 2024)\")\n",
    "    print(f\"Test:  {len(X_test):,} games (season 2025)\")\n",
    "    print(f\"Train away win rate: {y_train.mean():.1%}\")\n",
    "    print(f\"Test away win rate:  {y_test.mean():.1%}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, dates_train, dates_test, features\n",
    "\n",
    "# Create split (2022-2024 for model training/calib, 2025 for final test)\n",
    "print(\"=\" * 60)\n",
    "print(\"L10 Dataset Split:\")\n",
    "print(\"=\" * 60)\n",
    "X_train, X_test, y_train, y_test, dates_train, dates_test, features = create_train_test_split(\n",
    "    df_L10, features_L10\n",
    ")\n",
    "\n",
    "# Further split training data into model training (75%) and calibration (25%)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Three-Way Split (Training + Calibration + Test):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "split_idx = int(len(X_train) * 0.75)\n",
    "X_train_model = X_train.iloc[:split_idx]\n",
    "y_train_model = y_train.iloc[:split_idx]\n",
    "dates_train_model = dates_train.iloc[:split_idx]\n",
    "\n",
    "X_calib = X_train.iloc[split_idx:]\n",
    "y_calib = y_train.iloc[split_idx:]\n",
    "dates_calib = dates_train.iloc[split_idx:]\n",
    "\n",
    "print(f\"\\nTraining (model fit + CV):   {len(X_train_model):,} games (75%)\")\n",
    "print(f\"Calibration (isotonic fit): {len(X_calib):,} games (25%)\")\n",
    "print(f\"Test (final eval):          {len(X_test):,} games (2025)\")\n",
    "print(f\"\\nTraining away win rate: {y_train_model.mean():.1%}\")\n",
    "print(f\"Calibration away win rate: {y_calib.mean():.1%}\")\n",
    "print(f\"Test away win rate: {y_test.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0bb143",
   "metadata": {},
   "source": [
    "## 4. Train CatBoost Models with Different Hyperparameters\n",
    "\n",
    "Test multiple hyperparameter configurations and select the best one based on CV performance. Use randomsearch for speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c607fc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter search will use: 2,897 games (75%)\n",
      "Isotonic calibration will use: 966 games (25%)\n",
      "Final evaluation will use: 1,282 games (2025)\n"
     ]
    }
   ],
   "source": [
    "# Note: Using only X_train_model (75%) for hyperparameter search\n",
    "# X_calib (25%) is reserved exclusively for isotonic regression fitting\n",
    "print(f\"\\nHyperparameter search will use: {len(X_train_model):,} games (75%)\")\n",
    "print(f\"Isotonic calibration will use: {len(X_calib):,} games (25%)\")\n",
    "print(f\"Final evaluation will use: {len(X_test):,} games (2025)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4609b40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HYPERPARAMETER TUNING WITH RANDOMIZED SEARCH\n",
      "================================================================================\n",
      "\n",
      "Running RandomizedSearchCV with 10 random configurations...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "================================================================================\n",
      "HYPERPARAMETER SEARCH RESULTS\n",
      "================================================================================\n",
      "\n",
      "Best Parameters Found: {'depth': 3, 'iterations': 1000, 'learning_rate': 0.01}\n",
      "Best Cross-Validation Log Loss: 0.6527\n",
      "\n",
      "Evaluating best model on test set (2025 season)...\n",
      "\n",
      "Test Set Performance (2025 season - FINAL EVALUATION):\n",
      "Not Finalized, needs probability calibration before final results\n",
      "  • AUC-ROC:  0.6871\n",
      "  • Log Loss: 0.6364\n",
      "\n",
      "================================================================================\n",
      "HYPERPARAMETER SEARCH RESULTS\n",
      "================================================================================\n",
      "\n",
      "Best Parameters Found: {'depth': 3, 'iterations': 1000, 'learning_rate': 0.01}\n",
      "Best Cross-Validation Log Loss: 0.6527\n",
      "\n",
      "Evaluating best model on test set (2025 season)...\n",
      "\n",
      "Test Set Performance (2025 season - FINAL EVALUATION):\n",
      "Not Finalized, needs probability calibration before final results\n",
      "  • AUC-ROC:  0.6871\n",
      "  • Log Loss: 0.6364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"HYPERPARAMETER TUNING WITH RANDOMIZED SEARCH\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\n",
    "# Define parameter distribution for random search\n",
    "param_dist = {\n",
    "    'depth': randint(2, 7),                    # Range 2-6 (depth of trees)\n",
    "    'learning_rate': [0.01, 0.05, 0.1],       # Learning rate options\n",
    "    'iterations': [300, 500, 750, 1000]       # Number of boosting rounds\n",
    "}\n",
    "\n",
    "# Create base CatBoost model\n",
    "base_model = CatBoostClassifier(\n",
    "    random_state=42,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',  # Early stopping based on AUC, but we optimize Log Loss\n",
    "    task_type='CPU',\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Randomized Search with 10 iterations (tests 10 random combinations)\n",
    "print(\"\\nRunning RandomizedSearchCV with 10 random configurations...\")\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Number of random combinations to try\n",
    "    cv=5,       # 5-fold cross-validation on X_train\n",
    "    scoring='neg_log_loss',  # Optimize for LOG LOSS (lower is better)\n",
    "    n_jobs=-1, \n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on model training data ONLY (uses 5-fold CV internally for hyperparameter selection)\n",
    "# Calibration set is held completely separate\n",
    "random_search.fit(X_train_model, y_train_model)\n",
    "\n",
    "# Get best model and parameters\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "best_model_name = f\"Best (depth={best_params['depth']}, lr={best_params['learning_rate']}, iter={best_params['iterations']})\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HYPERPARAMETER SEARCH RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nBest Parameters Found: {best_params}\")\n",
    "print(f\"Best Cross-Validation Log Loss: {-random_search.best_score_:.4f}\")  # Negate because scoring is neg_log_loss\n",
    "\n",
    "# Evaluate on test set (final evaluation)\n",
    "print(f\"\\nEvaluating best model on test set (2025 season)...\")\n",
    "y_test_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "test_logloss = log_loss(y_test, y_test_pred_proba)\n",
    "\n",
    "print(f\"\\nTest Set Performance (2025 season - FINAL EVALUATION):\")\n",
    "print( \"Not Finalized, needs probability calibration before final results\")\n",
    "print(f\"  • AUC-ROC:  {test_auc:.4f}\")\n",
    "print(f\"  • Log Loss: {test_logloss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7980dbb",
   "metadata": {},
   "source": [
    "## 5. Probability Calibration: Isotonic Regression on Held-Out Data\n",
    "\n",
    "CatBoost probabilities can be poorly calibrated. We use Isotonic Regression fit on the held-out calibration set (X_calib, 25% of training data) to fix this.\n",
    "\n",
    "**Key Principle:** Calibrator is fit on X_calib (never seen during model training), ensuring no data leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1223df94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PROBABILITY CALIBRATION: ISOTONIC REGRESSION\n",
      "================================================================================\n",
      "\n",
      "Isotonic regression is fit on HELD-OUT data (X_calib).\n",
      "This ensures the calibration is independent of model training and test evaluation.\n",
      "\n",
      "  Calibrator fitted successfully on 966 games\n",
      "\n",
      "Uncalibrated test probs - Min: 0.1204, Max: 0.7871\n",
      "Uncalibrated test probs - Mean: 0.4254, Std: 0.1462\n",
      "\n",
      "Calibrated test probs - Min: 0.0000, Max: 1.0000\n",
      "Calibrated test probs - Mean: 0.4779, Std: 0.1730\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"PROBABILITY CALIBRATION: ISOTONIC REGRESSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "Isotonic regression is fit on HELD-OUT data (X_calib).\n",
    "This ensures the calibration is independent of model training and test evaluation.\n",
    "\"\"\")\n",
    "\n",
    "# Step 1: Get uncalibrated probabilities on held-out calibration set\n",
    "calib_probs_uncalibrated = best_model.predict_proba(X_calib)[:, 1]\n",
    "\n",
    "# Step 2: Fit isotonic regression on held-out calibration set\n",
    "calibrator = IsotonicRegression(out_of_bounds='clip')\n",
    "calibrator.fit(calib_probs_uncalibrated, y_calib)\n",
    "print(f\"  Calibrator fitted successfully on {len(X_calib):,} games\")\n",
    "\n",
    "# Step 3: Get uncalibrated test predictions\n",
    "test_probs_uncalibrated = best_model.predict_proba(X_test)[:, 1]\n",
    "test_probs_calibrated = calibrator.predict(test_probs_uncalibrated)\n",
    "\n",
    "print(f\"\\nUncalibrated test probs - Min: {test_probs_uncalibrated.min():.4f}, Max: {test_probs_uncalibrated.max():.4f}\")\n",
    "print(f\"Uncalibrated test probs - Mean: {test_probs_uncalibrated.mean():.4f}, Std: {test_probs_uncalibrated.std():.4f}\")\n",
    "print(f\"\\nCalibrated test probs - Min: {test_probs_calibrated.min():.4f}, Max: {test_probs_calibrated.max():.4f}\")\n",
    "print(f\"Calibrated test probs - Mean: {test_probs_calibrated.mean():.4f}, Std: {test_probs_calibrated.std():.4f}\")\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff2849",
   "metadata": {},
   "source": [
    "## 6. Evaluate Calibrated vs Uncalibrated Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb1451f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CALIBRATION EVALUATION: Uncalibrated vs Isotonic-Calibrated\n",
      "================================================================================\n",
      "\n",
      "Test Set Performance (2025 season):\n",
      "Comparing uncalibrated vs isotonic-calibrated predictions\n",
      "\n",
      "\n",
      "     Metric Uncalibrated Calibrated\n",
      "   Accuracy       0.6381     0.6365\n",
      "    AUC-ROC       0.6871     0.6804\n",
      "   Log Loss       0.6364     0.8230\n",
      "Brier Score       0.2229     0.2254\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "INTERPRETATION:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Log Loss & Brier Score (lower is better):\n",
      "  • Positive improvement = calibration reduced these values (better)\n",
      "\n",
      "Accuracy & AUC (higher is better):\n",
      "  • Positive improvement = calibration increased these values (better)\n",
      "\n",
      "Note: Calibration primarily improves Log Loss (probability accuracy)\n",
      "      Accuracy/AUC may not change significantly\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CALIBRATION EVALUATION: Uncalibrated vs Isotonic-Calibrated\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def evaluate_predictions(y_true, probs_uncalibrated, probs_calibrated):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of calibrated vs uncalibrated probabilities.\n",
    "    \"\"\"\n",
    "    results_dict = {\n",
    "        'Metric': [],\n",
    "        'Uncalibrated': [],\n",
    "        'Calibrated': [],\n",
    "    }\n",
    "    \n",
    "    metrics = [\n",
    "        ('Accuracy', lambda p: accuracy_score(y_true, p > 0.5)),\n",
    "        ('AUC-ROC', lambda p: roc_auc_score(y_true, p)),\n",
    "        ('Log Loss', lambda p: log_loss(y_true, p)),\n",
    "        ('Brier Score', lambda p: brier_score_loss(y_true, p)),\n",
    "    ]\n",
    "    #eg. for accuracy, accuracy_score (metric name, metric function)\n",
    "    for metric_name, metric_fn in metrics:\n",
    "        #get each score for calibrated/uncalibrated\n",
    "        uncalibrated_score = metric_fn(probs_uncalibrated)\n",
    "        calibrated_score = metric_fn(probs_calibrated)\n",
    "\n",
    "        results_dict['Metric'].append(metric_name)\n",
    "        results_dict['Uncalibrated'].append(f\"{uncalibrated_score:.4f}\")\n",
    "        results_dict['Calibrated'].append(f\"{calibrated_score:.4f}\")\n",
    "    \n",
    "    return pd.DataFrame(results_dict)\n",
    "\n",
    "print(\"\\nTest Set Performance (2025 season):\")\n",
    "print(\"Comparing uncalibrated vs isotonic-calibrated predictions\\n\")\n",
    "\n",
    "evaluation_df = evaluate_predictions(y_test, test_probs_uncalibrated, test_probs_calibrated)\n",
    "print(\"\\n\" + evaluation_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nLog Loss & Brier Score (lower is better):\")\n",
    "print(\"  • Positive improvement = calibration reduced these values (better)\")\n",
    "print(\"\\nAccuracy & AUC (higher is better):\")\n",
    "print(\"  • Positive improvement = calibration increased these values (better)\")\n",
    "print(\"\\nNote: Calibration primarily improves Log Loss (probability accuracy)\")\n",
    "print(\"      Accuracy/AUC may not change significantly\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
