{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e828ba2",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "715d4af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in ./.venv/lib/python3.9/site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in ./.venv/lib/python3.9/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (from catboost) (3.9.4)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in ./.venv/lib/python3.9/site-packages (from catboost) (2.0.2)\n",
      "Requirement already satisfied: pandas>=0.24 in ./.venv/lib/python3.9/site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.9/site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in ./.venv/lib/python3.9/site-packages (from catboost) (6.5.0)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.9/site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (3.2.5)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->catboost) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.23.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./.venv/lib/python3.9/site-packages (from plotly->catboost) (2.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "All packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install missing package for Jupyter (magic command)\n",
    "%pip install catboost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, classification_report,\n",
    "    confusion_matrix, log_loss, brier_score_loss, roc_curve\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "print(\"All packages loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9636e16",
   "metadata": {},
   "source": [
    "## 2. Load L10 Dataset (Best Performing Window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e484c1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 5,145 matchups\n",
      "Seasons: [np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
      "\n",
      "Games per season:\n",
      "season\n",
      "2022    1290\n",
      "2023    1288\n",
      "2024    1285\n",
      "2025    1282\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the L10 dataset (confirmed as best from LASSO analysis)\n",
    "df_L10 = pd.read_csv('nba_matchups_with_features_L10.csv')\n",
    "\n",
    "# Convert date columns\n",
    "df_L10['date'] = pd.to_datetime(df_L10['date'])\n",
    "\n",
    "print(f\"Dataset loaded: {len(df_L10):,} matchups\")\n",
    "print(f\"Seasons: {sorted(df_L10['season'].unique())}\")\n",
    "print(f\"\\nGames per season:\")\n",
    "print(df_L10['season'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359da98",
   "metadata": {},
   "source": [
    "## 3. Define Features and Create Train/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264ac1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base features (L10): 18\n",
      "\n",
      "Features:\n",
      "   1. off_rtg_L10_diff\n",
      "   2. def_rtg_L10_diff\n",
      "   3. net_rtg_L10_diff\n",
      "   4. efg_pct_L10_diff\n",
      "   5. 3p_pct_L10_diff\n",
      "   6. 3pa_rate_L10_diff\n",
      "   7. win_pct_L10_diff\n",
      "   8. to_pct_L10_diff\n",
      "   9. ft_rate_L10_diff\n",
      "  10. oreb_pct_L10_diff\n",
      "  11. ast_ratio_L10_diff\n",
      "  12. stl_pct_L10_diff\n",
      "  13. blk_pct_L10_diff\n",
      "  14. pts_std_L10_diff\n",
      "  15. win_streak_diff\n",
      "  16. rest_advantage\n",
      "  17. is_b2b_home\n",
      "  18. is_b2b_away\n"
     ]
    }
   ],
   "source": [
    "def get_features_L10():\n",
    "    \"\"\"\n",
    "    Return list of base features for L10 window.\n",
    "    Features are differential (away - home) unless noted.\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        # Advanced Efficiency Gaps\n",
    "        'off_rtg_L10_diff',       # Offensive efficiency gap\n",
    "        'def_rtg_L10_diff',       # Defensive efficiency gap\n",
    "        'net_rtg_L10_diff',       # Net rating gap\n",
    "        \n",
    "        # Shooting Efficiency Gaps\n",
    "        'efg_pct_L10_diff',       # Effective FG% gap\n",
    "        '3p_pct_L10_diff',        # 3-point shooting gap\n",
    "        '3pa_rate_L10_diff',      # 3-point volume gap\n",
    "        \n",
    "        # Form/Momentum\n",
    "        'win_pct_L10_diff',       # Recent win percentage gap\n",
    "        \n",
    "        # Ball Control\n",
    "        'to_pct_L10_diff',        # Turnover rate gap\n",
    "        'ft_rate_L10_diff',       # Free throw rate gap\n",
    "        \n",
    "        # Rebounding & Playmaking\n",
    "        'oreb_pct_L10_diff',      # Offensive rebounding gap\n",
    "        'ast_ratio_L10_diff',     # Assist ratio gap\n",
    "        \n",
    "        # Defensive Stats\n",
    "        'stl_pct_L10_diff',       # Steal percentage gap\n",
    "        'blk_pct_L10_diff',       # Block percentage gap\n",
    "        \n",
    "        # Consistency & Momentum (non-window features)\n",
    "        'pts_std_L10_diff',       # Scoring consistency gap\n",
    "        'win_streak_diff',        # Win streak differential\n",
    "        \n",
    "        # Rest/Fatigue\n",
    "        'rest_advantage',         # Rest days advantage\n",
    "        'is_b2b_home',            # Home team back-to-back\n",
    "        'is_b2b_away'             # Away team back-to-back\n",
    "    ]\n",
    "    \n",
    "    return features\n",
    "\n",
    "features_L10 = get_features_L10()\n",
    "\n",
    "print(f\"Base features (L10): {len(features_L10)}\")\n",
    "print(\"\\nFeatures:\")\n",
    "for i, f in enumerate(features_L10, 1):\n",
    "    print(f\"  {i:2d}. {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b86caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "L10 Dataset Split:\n",
      "============================================================\n",
      "Train: 3,863 games (seasons ≤ 2024)\n",
      "Test:  1,282 games (season 2025)\n",
      "Train away win rate: 44.1%\n",
      "Test away win rate:  45.2%\n"
     ]
    }
   ],
   "source": [
    "def create_train_test_split(df, features, target='win_away'):\n",
    "    \"\"\"\n",
    "    Split data into train (≤2024) and test (2025) sets.\n",
    "    Returns X_train, X_test, y_train, y_test, dates\n",
    "    \"\"\"\n",
    "    # Verify all features exist\n",
    "    missing = [f for f in features if f not in df.columns]\n",
    "    if missing:\n",
    "        print(f\"Warning: Missing features: {missing}\")\n",
    "        features = [f for f in features if f in df.columns]\n",
    "    \n",
    "    # Drop any rows with missing values in features or target\n",
    "    df_clean = df.dropna(subset=features + [target])\n",
    "    \n",
    "    # Split by season\n",
    "    train_mask = df_clean['season'] <= 2024\n",
    "    test_mask = df_clean['season'] == 2025\n",
    "    \n",
    "    X_train = df_clean.loc[train_mask, features].copy()\n",
    "    X_test = df_clean.loc[test_mask, features].copy()\n",
    "    y_train = df_clean.loc[train_mask, target].copy()\n",
    "    y_test = df_clean.loc[test_mask, target].copy()\n",
    "    \n",
    "    # Store dates for analysis\n",
    "    dates_train = df_clean.loc[train_mask, 'date'].copy()\n",
    "    dates_test = df_clean.loc[test_mask, 'date'].copy()\n",
    "    \n",
    "    print(f\"Train: {len(X_train):,} games (seasons ≤ 2024)\")\n",
    "    print(f\"Test:  {len(X_test):,} games (season 2025)\")\n",
    "    print(f\"Train away win rate: {y_train.mean():.1%}\")\n",
    "    print(f\"Test away win rate:  {y_test.mean():.1%}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, dates_train, dates_test, features\n",
    "\n",
    "# Create split (2022-2024 for model training, 2025 for final test)\n",
    "print(\"=\" * 60)\n",
    "print(\"L10 Dataset Split:\")\n",
    "print(\"=\" * 60)\n",
    "X_train, X_test, y_train, y_test, dates_train, dates_test, features = create_train_test_split(\n",
    "    df_L10, features_L10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0bb143",
   "metadata": {},
   "source": [
    "## 4. Train CatBoost Models with Different Hyperparameters\n",
    "\n",
    "Test multiple hyperparameter configurations and select the best one based on CV performance. Use randomsearch for speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4609b40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HYPERPARAMETER TUNING WITH RANDOMIZED SEARCH\n",
      "================================================================================\n",
      "\n",
      "Running RandomizedSearchCV with 10 random configurations...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "================================================================================\n",
      "HYPERPARAMETER SEARCH RESULTS\n",
      "================================================================================\n",
      "\n",
      "Best Parameters Found: {'depth': 3, 'iterations': 1000, 'learning_rate': 0.01}\n",
      "Best Cross-Validation Log Loss: 0.6570\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"HYPERPARAMETER TUNING WITH RANDOMIZED SEARCH\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\n",
    "# Define parameter distribution for random search\n",
    "param_dist = {\n",
    "    'depth': randint(2, 7),                    # Range 2-6 (depth of trees)\n",
    "    'learning_rate': [0.01, 0.05, 0.1],       # Learning rate options\n",
    "    'iterations': [300, 500, 750, 1000]       # Number of boosting rounds\n",
    "}\n",
    "\n",
    "# Create base CatBoost model\n",
    "base_model = CatBoostClassifier(\n",
    "    random_state=42,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',  # Early stopping based on AUC, but we optimize Log Loss\n",
    "    task_type='CPU',\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Randomized Search with 10 iterations (tests 10 random combinations)\n",
    "print(\"\\nRunning RandomizedSearchCV with 10 random configurations...\")\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Number of random combinations to try\n",
    "    cv=5,       # 5-fold cross-validation on X_train\n",
    "    scoring='neg_log_loss',  # Optimize for LOG LOSS (lower is better)\n",
    "    n_jobs=-1, \n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on model training data ONLY (uses 5-fold CV internally for hyperparameter selection)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model and parameters\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "best_model_name = f\"Best (depth={best_params['depth']}, lr={best_params['learning_rate']}, iter={best_params['iterations']})\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HYPERPARAMETER SEARCH RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nBest Parameters Found: {best_params}\")\n",
    "print(f\"Best Cross-Validation Log Loss: {-random_search.best_score_:.4f}\")  # Negate because scoring is neg_log_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1223df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get predictions\n",
    "test_probs= best_model.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff2849",
   "metadata": {},
   "source": [
    "## 6. Evaluate Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb1451f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Performance (2025 season):\n",
      "\n",
      "     Metric  Score\n",
      "   Accuracy 0.6466\n",
      "    AUC-ROC 0.6894\n",
      "   Log Loss 0.6334\n",
      "Brier Score 0.2215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_predictions(y_true, probs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    results_dict = {\n",
    "        'Metric': [],\n",
    "        'Score': [],\n",
    "    }\n",
    "    \n",
    "    metrics = [\n",
    "        ('Accuracy', lambda p: accuracy_score(y_true, p > 0.5)),\n",
    "        ('AUC-ROC', lambda p: roc_auc_score(y_true, p)),\n",
    "        ('Log Loss', lambda p: log_loss(y_true, p)),\n",
    "        ('Brier Score', lambda p: brier_score_loss(y_true, p)),\n",
    "    ]\n",
    "    #eg. for accuracy, accuracy_score (metric name, metric function)\n",
    "    for metric_name, metric_fn in metrics:\n",
    "        score = metric_fn(probs)\n",
    "\n",
    "        results_dict['Metric'].append(metric_name)\n",
    "        results_dict['Score'].append(f\"{score:.4f}\")\n",
    "    \n",
    "    return pd.DataFrame(results_dict)\n",
    "\n",
    "print(\"\\nTest Set Performance (2025 season):\")\n",
    "\n",
    "evaluation_df = evaluate_predictions(y_test, test_probs)\n",
    "print(\"\\n\" + evaluation_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
